{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17202725",
   "metadata": {},
   "source": [
    "# Fine-tuning BERTweet for Sentiment Analysis\n",
    "\n",
    "This notebook demonstrates how to fine-tune the BERTweet model for sentiment analysis and save the result in PKL format for later use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c012a8",
   "metadata": {},
   "source": [
    "## 1. Install Required Packages\n",
    "\n",
    "First, let's install the necessary packages for fine-tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8091d852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (1.26.4)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\queri\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (5.9.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (1.26.4)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\queri\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\queri\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (6.0.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\queri\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (6.0.1)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (2.6.0+cu118)Requirement already satisfied: torch>=2.0.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (2.6.0+cu118)\n",
      "\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (0.30.2)Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (0.30.2)\n",
      "\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (0.5.3)Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (0.5.3)\n",
      "\n",
      "Requirement already satisfied: filelock in c:\\users\\queri\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.16.1)Requirement already satisfied: filelock in c:\\users\\queri\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.16.1)\n",
      "\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.6.1)Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.6.1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# in one cell, *only* this line:\n",
    "%pip install --upgrade \"accelerate>=0.26.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c9d397a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\queri\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.66.5)\n",
      "\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.13.1)Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.13.1)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: networkx in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.3)Requirement already satisfied: networkx in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.3)\n",
      "\n",
      "Requirement already satisfied: jinja2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.4)Requirement already satisfied: jinja2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.4)\n",
      "\n",
      "Requirement already satisfied: setuptools in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (75.1.0)Requirement already satisfied: setuptools in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (75.1.0)\n",
      "\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.13.1)Requirement already satisfied: sympy==1.13.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.13.1)\n",
      "\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
      "\n",
      "Requirement already satisfied: colorama in c:\\users\\queri\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate>=0.26.0) (0.4.6)Requirement already satisfied: colorama in c:\\users\\queri\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate>=0.26.0) (0.4.6)\n",
      "\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (2.1.3)Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (2.1.3)\n",
      "\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.3.2)Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.3.2)\n",
      "\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.7)Requirement already satisfied: idna<4,>=2.5 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.7)\n",
      "\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.2.3)Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.2.3)\n",
      "\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.12.14)Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.12.14)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess, sys\n",
    "\n",
    "def ensure_accelerate(min_version=\"0.26.0\"):\n",
    "    try:\n",
    "        import accelerate\n",
    "        from packaging import version\n",
    "        if version.parse(accelerate.__version__) < version.parse(min_version):\n",
    "            raise ImportError\n",
    "    except ImportError:\n",
    "        print(f\"Installing/Upgrading accelerate>={min_version}â€¦\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\",\n",
    "                               \"install\", f\"accelerate>={min_version}\"])\n",
    "        # after installation you must restart the process to pick it up\n",
    "        print(\"Please restart the Python process now that accelerate is installed.\")\n",
    "        sys.exit(0)\n",
    "\n",
    "ensure_accelerate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "33a1c81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\queri\\anaconda3\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.26.4)\n",
      "\n",
      "Requirement already satisfied: filelock in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.21.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (4.66.5)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.6.0+cu118)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\queri\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (4.66.5)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.6.0+cu118)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\queri\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (75.1.0)Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\queri\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\queri\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0->transformers[torch]) (2.1.3)\n",
      "\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0->transformers[torch]) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"'accelerate\": Expected package name at the start of dependency specifier\n",
      "    'accelerate\n",
      "    ^\n",
      "\n",
      "    'accelerate\n",
      "    ^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\queri\\anaconda3\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "\n",
      "Requirement already satisfied: jinja2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\queri\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\queri\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\queri\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: nltk in c:\\users\\queri\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\queri\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\queri\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\queri\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\queri\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\queri\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\queri\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n",
      "\n",
      "    #\n",
      "    ^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\queri\\anaconda3\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (1.26.4)\n",
      "\n",
      "Requirement already satisfied: filelock in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (3.10.5)Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.4.0)\n",
      "\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\queri\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\queri\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\queri\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)Requirement already satisfied: scikit-learn in c:\\users\\queri\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "\n",
      "Requirement already satisfied: tqdm in c:\\users\\queri\\anaconda3\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\queri\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\queri\\anaconda3\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\queri\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\queri\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from pandas) (2024.1)Requirement already satisfied: pandas in c:\\users\\queri\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\queri\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)Requirement already satisfied: matplotlib in c:\\users\\queri\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\queri\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)Requirement already satisfied: seaborn in c:\\users\\queri\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\queri\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\queri\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\queri\\anaconda3\\lib\\site-packages (1.4.2)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install transformers[torch] --upgrade\n",
    "!pip install 'accelerate>=0.26.0'  # Required for Trainer with PyTorch\n",
    "!pip install torch\n",
    "!pip install nltk\n",
    "!pip install emoji==0.6.0  # Must use version 0.6.0 or 0.5.4 for compatibility\n",
    "!pip install datasets\n",
    "!pip install scikit-learn\n",
    "!pip install tqdm\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958aa097",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Setup TweetNormalizer\n",
    "\n",
    "Now let's import the necessary libraries and set up the TweetNormalizer for data preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3fbe20c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TweetNormalizer.py created successfully!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import joblib\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    EvalPrediction,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Create TweetNormalizer.py if it doesn't exist or has issues\n",
    "tweet_normalizer_content = '''\n",
    "# TweetNormalizer module for BERTweet\n",
    "# Based on https://github.com/VinAIResearch/BERTweet\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "def normalizeTweet(tweet):\n",
    "    \"\"\"\n",
    "    Normalize tweet text:\n",
    "    1. Replace URLs with HTTPURL\n",
    "    2. Replace user mentions with @USER\n",
    "    3. Replace emojis with text\n",
    "    4. Other normalizations for Twitter-specific content\n",
    "    \"\"\"\n",
    "    # Replace URLs with HTTPURL\n",
    "    tweet = re.sub(r\\'https?://\\\\S+\\', \\'HTTPURL\\', tweet)\n",
    "    \n",
    "    # Replace user mentions with @USER\n",
    "    tweet = re.sub(r\\'@\\\\w+\\', \\'@USER\\', tweet)\n",
    "    \n",
    "    # Replace emojis with text representation\n",
    "    tweet = emoji.demojize(tweet)\n",
    "    \n",
    "    # Other normalizations\n",
    "    tweet = tweet.replace(\\'#\\', \\' #\\')  # Add space before hashtags\n",
    "    tweet = re.sub(r\\'\\\\s+\\', \\' \\', tweet)  # Replace multiple spaces with single space\n",
    "    \n",
    "    return tweet.strip()\n",
    "'''\n",
    "\n",
    "with open('TweetNormalizer.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(tweet_normalizer_content)\n",
    "\n",
    "print(\"TweetNormalizer.py created successfully!\")\n",
    "\n",
    "from TweetNormalizer import normalizeTweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f22765a",
   "metadata": {},
   "source": [
    "## 3. Load and Prepare Dataset\n",
    "\n",
    "Load the sentiment140 dataset and prepare it for fine-tuning using a small sample for quick testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1e081e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset: ['0', '1467810369', 'Mon Apr 06 22:19:45 PDT 2009', 'NO_QUERY', '_TheSpecialOne_', \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\"]\n",
      " ['0', '1467810369', 'Mon Apr 06 22:19:45 PDT 2009', 'NO_QUERY', '_TheSpecialOne_', \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\"]\n",
      "\n",
      "Class distribution:\n",
      "target\n",
      "1    800000\n",
      "0    799999\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution:\n",
      "target\n",
      "1    800000\n",
      "0    799999\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data:\n",
      "                                                text  \\\n",
      "0                          today is a beautiful day    \n",
      "1  i've wasted my time making ANOTHER background!...   \n",
      "2  Ughh todays beach weather... But I have work. ...   \n",
      "3  @fashionesedaily @irlita @yunita_dee @Velasss ...   \n",
      "4      is working on a SUNDAY!!!!!!!!!!!!!!!!!!!!!!    \n",
      "\n",
      "                                     normalized_text  target  \n",
      "0                           today is a beautiful day       1  \n",
      "1  i've wasted my time making ANOTHER background!...       0  \n",
      "2  Ughh todays beach weather... But I have work. ...       0  \n",
      "3  @USER @USER @USER @USER @USER @USER @USER teri...       1  \n",
      "4       is working on a SUNDAY!!!!!!!!!!!!!!!!!!!!!!       0  \n",
      "\n",
      "Dataset size: 4992 tweets\n",
      "Class distribution in sample: target\n",
      "1    2496\n",
      "0    2496\n",
      "Name: count, dtype: int64\n",
      "Sample data:\n",
      "                                                text  \\\n",
      "0                          today is a beautiful day    \n",
      "1  i've wasted my time making ANOTHER background!...   \n",
      "2  Ughh todays beach weather... But I have work. ...   \n",
      "3  @fashionesedaily @irlita @yunita_dee @Velasss ...   \n",
      "4      is working on a SUNDAY!!!!!!!!!!!!!!!!!!!!!!    \n",
      "\n",
      "                                     normalized_text  target  \n",
      "0                           today is a beautiful day       1  \n",
      "1  i've wasted my time making ANOTHER background!...       0  \n",
      "2  Ughh todays beach weather... But I have work. ...       0  \n",
      "3  @USER @USER @USER @USER @USER @USER @USER teri...       1  \n",
      "4       is working on a SUNDAY!!!!!!!!!!!!!!!!!!!!!!       0  \n",
      "\n",
      "Dataset size: 4992 tweets\n",
      "Class distribution in sample: target\n",
      "1    2496\n",
      "0    2496\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Note: Using a small sample size of 5000 tweets for quick testing.\n",
      "For better model performance, increase the sample_size variable.\n",
      "\n",
      "\n",
      "Note: Using a small sample size of 5000 tweets for quick testing.\n",
      "For better model performance, increase the sample_size variable.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('sentiment140.csv', encoding='ISO-8859-1')\n",
    "print(\"Columns in the dataset:\", df.columns.tolist())\n",
    "\n",
    "# Rename columns if needed\n",
    "df.columns = ['target', 'id', 'date', 'flag', 'user', 'text']\n",
    "\n",
    "# Convert labels: Twitter Sentiment140 uses 0 for negative, 4 for positive\n",
    "# Convert to 0 for negative, 1 for positive for easier handling\n",
    "df['target'] = df['target'].replace(4, 1)\n",
    "\n",
    "# Verify balance of classes\n",
    "class_distribution = df['target'].value_counts()\n",
    "print(\"\\nClass distribution:\")\n",
    "print(class_distribution)\n",
    "\n",
    "# Normalize tweets with improved function to handle errors\n",
    "def safe_normalize(text):\n",
    "    try:\n",
    "        if pd.isna(text) or text == '':\n",
    "            return ''\n",
    "        return normalizeTweet(str(text))\n",
    "    except Exception as e:\n",
    "        print(f\"Error normalizing text: {str(e)}\")\n",
    "        return str(text)  # Return original text if normalization fails\n",
    "\n",
    "# Take a small sample first to verify the pipeline works\n",
    "# For actual training, you'll want to increase this number\n",
    "sample_size = 5000  # Small sample for quick testing and validation\n",
    "\n",
    "# Sample from the dataset before normalization to speed things up\n",
    "df_positive = df[df['target'] == 1].sample(sample_size//2, random_state=seed)\n",
    "df_negative = df[df['target'] == 0].sample(sample_size//2, random_state=seed)\n",
    "df_sample = pd.concat([df_positive, df_negative]).reset_index(drop=True)\n",
    "\n",
    "# Now normalize only the sampled data\n",
    "df_sample['normalized_text'] = df_sample['text'].apply(safe_normalize)\n",
    "\n",
    "# Filter out empty or extremely short tweets as they may not be useful for training\n",
    "df_sample = df_sample[df_sample['normalized_text'].str.len() > 5]\n",
    "\n",
    "# Rebalance if filtering removed any tweets\n",
    "if df_sample['target'].value_counts().size > 1:  # Check that both classes still exist\n",
    "    min_class_size = min(df_sample['target'].value_counts())\n",
    "    df_positive = df_sample[df_sample['target'] == 1].sample(min_class_size, random_state=seed)\n",
    "    df_negative = df_sample[df_sample['target'] == 0].sample(min_class_size, random_state=seed)\n",
    "    df_sample = pd.concat([df_positive, df_negative]).reset_index(drop=True)\n",
    "\n",
    "# Shuffle the data\n",
    "df_sample = df_sample.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "# Display some examples\n",
    "print(\"\\nSample data:\")\n",
    "print(df_sample[['text', 'normalized_text', 'target']].head())\n",
    "\n",
    "# Print dataset size\n",
    "print(f\"\\nDataset size: {len(df_sample)} tweets\")\n",
    "print(f\"Class distribution in sample: {df_sample['target'].value_counts()}\")\n",
    "print(\"\\nNote: Using a small sample size of {0} tweets for quick testing.\".format(sample_size))\n",
    "print(\"For better model performance, increase the sample_size variable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e261d99d",
   "metadata": {},
   "source": [
    "## 4. Split the Data and Create Datasets\n",
    "\n",
    "Split the data into training, validation, and test sets, and prepare the datasets for the Transformers library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8fa2edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 3494\n",
      "Validation set size: 749\n",
      "Testing set size: 749\n",
      "\n",
      "Training class distribution: target\n",
      "0    1747\n",
      "1    1747\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation set size: 749\n",
      "Testing set size: 749\n",
      "\n",
      "Training class distribution: target\n",
      "0    1747\n",
      "1    1747\n",
      "Name: count, dtype: int64\n",
      "Validation class distribution: target\n",
      "1    375\n",
      "0    374\n",
      "Name: count, dtype: int64\n",
      "Testing class distribution: target\n",
      "0    375\n",
      "1    374\n",
      "Name: count, dtype: int64\n",
      "Validation class distribution: target\n",
      "1    375\n",
      "0    374\n",
      "Name: count, dtype: int64\n",
      "Testing class distribution: target\n",
      "0    375\n",
      "1    374\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and temp (for validation and test)\n",
    "train_df, temp_df = train_test_split(df_sample, test_size=0.3, random_state=seed, stratify=df_sample['target'])\n",
    "# Split temp into validation and test\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=seed, stratify=temp_df['target'])\n",
    "\n",
    "# Convert pandas DataFrames to Hugging Face datasets\n",
    "train_dataset = Dataset.from_pandas(train_df[['normalized_text', 'target']])\n",
    "val_dataset = Dataset.from_pandas(val_df[['normalized_text', 'target']])\n",
    "test_dataset = Dataset.from_pandas(test_df[['normalized_text', 'target']])\n",
    "\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")\n",
    "print(f\"Testing set size: {len(test_dataset)}\")\n",
    "\n",
    "# Verify class balance\n",
    "print(f\"\\nTraining class distribution: {train_df['target'].value_counts()}\")\n",
    "print(f\"Validation class distribution: {val_df['target'].value_counts()}\")\n",
    "print(f\"Testing class distribution: {test_df['target'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d29e90f",
   "metadata": {},
   "source": [
    "## 5. Load BERTweet Model and Tokenizer\n",
    "\n",
    "Load the pre-trained BERTweet model and tokenizer with proper initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b6385086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vinai/bertweet-base for sequence classification with 2 labels\n",
      "Model config: RobertaConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n",
      "\n",
      "Model config: RobertaConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select BERTweet model\n",
    "model_name = \"vinai/bertweet-base\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load model with initialization appropriate for classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=2,\n",
    "    problem_type=\"single_label_classification\",\n",
    "    # Ensure proper weight initialization\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    hidden_dropout_prob=0.1,\n",
    "    classifier_dropout=0.1,\n",
    ")\n",
    "\n",
    "# Verify model config\n",
    "print(f\"Loaded {model_name} for sequence classification with 2 labels\")\n",
    "print(f\"Model config: {model.config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a1e45c",
   "metadata": {},
   "source": [
    "## 6. Tokenize the Datasets\n",
    "\n",
    "Prepare the datasets by tokenizing the texts with improved error handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ca384885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68257a541ec74f6b95a2c20fa06cf6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3494 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25af028ff0f44bc95f40a7670316fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/749 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28df9f2fc3bb455580c27ad744fa3720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/749 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets have been tokenized and formatted for PyTorch\n",
      "\n",
      "Sample input_ids length: 128\n",
      "Sample label: 0\n",
      "\n",
      "\n",
      "Sample input_ids length: 128\n",
      "Sample label: 0\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    \"\"\"Tokenize the texts with error handling\"\"\"\n",
    "    # Clean and validate input texts\n",
    "    texts = [str(text) if text else \"\" for text in examples['normalized_text']]\n",
    "    \n",
    "    # Use truncation and padding for consistent lengths\n",
    "    return tokenizer(\n",
    "        texts, \n",
    "        padding='max_length', \n",
    "        truncation=True, \n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set the format for PyTorch - FIX: Use tokenized datasets for renaming columns\n",
    "tokenized_train_dataset = tokenized_train_dataset.rename_column(\"target\", \"labels\")\n",
    "tokenized_val_dataset = tokenized_val_dataset.rename_column(\"target\", \"labels\")  # Fixed: was using val_dataset\n",
    "tokenized_test_dataset = tokenized_test_dataset.rename_column(\"target\", \"labels\")  # Fixed: was using test_dataset\n",
    "\n",
    "tokenized_train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "tokenized_val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "tokenized_test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "print(\"Datasets have been tokenized and formatted for PyTorch\")\n",
    "\n",
    "# Check a sample of tokenized data\n",
    "sample_item = tokenized_train_dataset[0]\n",
    "print(f\"\\nSample input_ids length: {len(sample_item['input_ids'])}\")\n",
    "print(f\"Sample label: {sample_item['labels']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf4075c",
   "metadata": {},
   "source": [
    "## 7. Define Training Arguments and Metrics\n",
    "\n",
    "Define the training configuration and evaluation metrics with fixes for zero-division warnings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc23ff7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using IntervalStrategy for both evaluation and saving (older transformers version)\n",
      "Class weights - Negative: 1.0000, Positive: 1.0000\n",
      "Class weights - Negative: 1.0000, Positive: 1.0000\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "--load_best_model_at_end requires the save and eval strategy to match, but found\n- Evaluation strategy: IntervalStrategy.NO\n- Save strategy: SaveStrategy.STEPS",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: Could not remove checkpoint directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Define optimized training arguments for the small sample\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m     47\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39mcheckpoint_dir,\n\u001b[0;32m     48\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Reduced epochs for faster testing\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     per_device_train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,  \u001b[38;5;66;03m# Smaller batch size\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     per_device_eval_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     51\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m,  \u001b[38;5;66;03m# Lower learning rate for stability\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[0;32m     53\u001b[0m     logging_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./logs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     54\u001b[0m     logging_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,  \u001b[38;5;66;03m# More frequent logging for small dataset\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     eval_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,  \u001b[38;5;66;03m# Evaluate more frequently with small dataset\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     save_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     57\u001b[0m     save_total_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     58\u001b[0m     load_best_model_at_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# Load the best model at the end of training\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     metric_for_best_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Use F1 score to determine best model\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     save_safetensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     61\u001b[0m     save_strategy\u001b[38;5;241m=\u001b[39mSaveStrategy\u001b[38;5;241m.\u001b[39mSTEPS,  \u001b[38;5;66;03m# Use appropriate strategy based on availability\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     dataloader_num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,  \u001b[38;5;66;03m# Reduced for small dataset\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     optim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madamw_torch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     64\u001b[0m     warmup_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,  \u001b[38;5;66;03m# Warm up learning rate over 10% of steps\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     gradient_accumulation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,  \u001b[38;5;66;03m# Smaller accumulation for small dataset\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     fp16\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available(),  \u001b[38;5;66;03m# Use mixed precision if available\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# Disable wandb reporting\u001b[39;00m\n\u001b[0;32m     68\u001b[0m )\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining arguments initialized successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m<string>:132\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, tp_size, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, eval_use_gather_object, average_tokens_across_devices)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\queri\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1648\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_best_model_at_end \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_strategy \u001b[38;5;241m!=\u001b[39m SaveStrategy\u001b[38;5;241m.\u001b[39mBEST:\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_strategy \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_strategy:\n\u001b[1;32m-> 1648\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1649\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--load_best_model_at_end requires the save and eval strategy to match, but found\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m- Evaluation \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1650\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrategy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_strategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m- Save strategy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_strategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1651\u001b[0m         )\n\u001b[0;32m   1652\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_strategy \u001b[38;5;241m==\u001b[39m IntervalStrategy\u001b[38;5;241m.\u001b[39mSTEPS \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_steps \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_steps \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1653\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_steps \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_steps \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: --load_best_model_at_end requires the save and eval strategy to match, but found\n- Evaluation strategy: IntervalStrategy.NO\n- Save strategy: SaveStrategy.STEPS"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, get_scheduler\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import os\n",
    "import inspect\n",
    "\n",
    "# Define compute_metrics function for evaluation with zero_division handling\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # Use zero_division=0 to handle cases where a class has no predictions\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"precision\": precision_score(labels, preds, zero_division=0),\n",
    "        \"recall\": recall_score(labels, preds, zero_division=0),\n",
    "        \"f1\": f1_score(labels, preds, zero_division=0),\n",
    "    }\n",
    "\n",
    "# Calculate class weights to handle any imbalance\n",
    "total = len(df_sample)\n",
    "neg_weight = total / (2 * (df_sample['target'] == 0).sum())\n",
    "pos_weight = total / (2 * (df_sample['target'] == 1).sum())\n",
    "print(f\"Class weights - Negative: {neg_weight:.4f}, Positive: {pos_weight:.4f}\")\n",
    "\n",
    "# Clean up any existing checkpoints to start fresh\n",
    "checkpoint_dir = \"./bertweet-sentiment\"\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    import shutil\n",
    "    try:\n",
    "        print(f\"Removing old checkpoint directory: {checkpoint_dir}\")\n",
    "        shutil.rmtree(checkpoint_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not remove checkpoint directory: {str(e)}\")\n",
    "\n",
    "# Check which arguments are supported by this version of transformers\n",
    "training_args_params = inspect.signature(TrainingArguments).parameters\n",
    "args_dict = {\n",
    "    \"output_dir\": checkpoint_dir,\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"per_device_train_batch_size\": 16,\n",
    "    \"per_device_eval_batch_size\": 32,\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"logging_dir\": \"./logs\",\n",
    "    \"logging_steps\": 10,\n",
    "    \"save_steps\": 50,\n",
    "    \"save_total_limit\": 1,\n",
    "    \"dataloader_num_workers\": 2,\n",
    "    \"fp16\": torch.cuda.is_available(),\n",
    "}\n",
    "\n",
    "# Add optional parameters only if supported\n",
    "if \"eval_steps\" in training_args_params:\n",
    "    args_dict[\"eval_steps\"] = 50\n",
    "\n",
    "if \"evaluation_strategy\" in training_args_params:\n",
    "    # Import and use IntervalStrategy if available\n",
    "    try:\n",
    "        from transformers import IntervalStrategy\n",
    "        args_dict[\"evaluation_strategy\"] = IntervalStrategy.STEPS\n",
    "    except ImportError:\n",
    "        # Fallback to string version\n",
    "        args_dict[\"evaluation_strategy\"] = \"steps\"\n",
    "elif \"eval_strategy\" in training_args_params:  # older versions\n",
    "    args_dict[\"eval_strategy\"] = \"steps\"\n",
    "\n",
    "if \"save_strategy\" in training_args_params:\n",
    "    # Import and use SaveStrategy if available\n",
    "    try:\n",
    "        from transformers import SaveStrategy\n",
    "        args_dict[\"save_strategy\"] = SaveStrategy.STEPS\n",
    "    except ImportError:\n",
    "        # Fallback to string version\n",
    "        args_dict[\"save_strategy\"] = \"steps\"\n",
    "\n",
    "if \"load_best_model_at_end\" in training_args_params:\n",
    "    args_dict[\"load_best_model_at_end\"] = True\n",
    "    \n",
    "if \"metric_for_best_model\" in training_args_params:\n",
    "    args_dict[\"metric_for_best_model\"] = \"f1\"\n",
    "\n",
    "if \"optim\" in training_args_params:\n",
    "    args_dict[\"optim\"] = \"adamw_torch\"\n",
    "\n",
    "if \"warmup_ratio\" in training_args_params:\n",
    "    args_dict[\"warmup_ratio\"] = 0.1\n",
    "\n",
    "if \"gradient_accumulation_steps\" in training_args_params:\n",
    "    args_dict[\"gradient_accumulation_steps\"] = 2\n",
    "\n",
    "if \"report_to\" in training_args_params:\n",
    "    args_dict[\"report_to\"] = None\n",
    "\n",
    "if \"save_safetensors\" in training_args_params:\n",
    "    args_dict[\"save_safetensors\"] = True\n",
    "\n",
    "# Create training arguments with only supported parameters\n",
    "training_args = TrainingArguments(**args_dict)\n",
    "\n",
    "print(\"Training arguments initialized successfully with compatible settings\")\n",
    "print(f\"Using output_dir: {training_args.output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc2081b",
   "metadata": {},
   "source": [
    "## 8. Create Custom Loss Function For Class Weights\n",
    "\n",
    "Create a custom Trainer class to incorporate class weights into the training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class WeightedLossTrainer(Trainer):\n",
    "    \"\"\"Custom trainer class that applies weighted loss\"\"\"\n",
    "    def __init__(self, class_weights=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "        \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        if self.class_weights is not None:\n",
    "            # Apply class weights to the loss\n",
    "            weights = torch.tensor(self.class_weights, device=labels.device)\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=weights)\n",
    "            loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        else:\n",
    "            # Standard loss if no class weights\n",
    "            loss = F.cross_entropy(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Apply class weights\n",
    "class_weights = [neg_weight, pos_weight]\n",
    "print(f\"Using class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296ed0bf",
   "metadata": {},
   "source": [
    "## 9. Create Trainer and Fine-tune the Model\n",
    "\n",
    "Initialize the Trainer with our custom weighted loss and fine-tune BERTweet on the sentiment dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0368dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Trainer with custom weighted loss\n",
    "trainer = WeightedLossTrainer(\n",
    "    class_weights=class_weights,\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,  # Use validation set during training\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]  # Stop if no improvement for 3 evaluations\n",
    ")\n",
    "\n",
    "# Record start time\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "print(f\"Starting fine-tuning at {start_time}\")\n",
    "print(f\"Training on {len(tokenized_train_dataset)} examples, validating on {len(tokenized_val_dataset)} examples\")\n",
    "print(\"Using small sample size for quick testing - this should complete in minutes\")\n",
    "\n",
    "# Fine-tune the model\n",
    "try:\n",
    "    trainer.train()\n",
    "    print(\"Training completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Training error: {str(e)}\")\n",
    "    print(\"Attempting to continue with reduced settings...\")\n",
    "    \n",
    "    # Try again with more conservative settings\n",
    "    training_args.per_device_train_batch_size = 8\n",
    "    training_args.gradient_accumulation_steps = 1\n",
    "    training_args.fp16 = False\n",
    "    \n",
    "    trainer = WeightedLossTrainer(\n",
    "        class_weights=class_weights,\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train_dataset,\n",
    "        eval_dataset=tokenized_val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "# Record end time\n",
    "end_time = datetime.now()\n",
    "training_duration = end_time - start_time\n",
    "print(f\"Fine-tuning complete at {end_time}!\")\n",
    "print(f\"Training duration: {training_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab52aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model with safetensors format\n",
    "try:\n",
    "    # Create a separate directory for the final model\n",
    "    final_model_dir = \"./bertweet-sentiment-final\"\n",
    "    os.makedirs(final_model_dir, exist_ok=True)\n",
    "    \n",
    "    # Save just the model weights (no optimizer state)\n",
    "    model.save_pretrained(final_model_dir, safe_serialization=True)\n",
    "    tokenizer.save_pretrained(final_model_dir)\n",
    "    \n",
    "    print(f\"Final model saved successfully to {final_model_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving final model: {str(e)}\")\n",
    "    print(\"You can still use the model in memory for evaluation and predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcd3bcd",
   "metadata": {},
   "source": [
    "## 10. Evaluate the Fine-tuned Model\n",
    "\n",
    "Evaluate the fine-tuned model on the test dataset with detailed metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab2581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate(eval_dataset=tokenized_test_dataset)\n",
    "print(f\"Evaluation results: {eval_results}\")\n",
    "\n",
    "# Get predictions for confusion matrix\n",
    "predictions = trainer.predict(tokenized_test_dataset)\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "labels = tokenized_test_dataset['labels'].numpy()\n",
    "\n",
    "# Print more detailed metrics\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "precision = precision_score(labels, preds, zero_division=0)\n",
    "recall = recall_score(labels, preds, zero_division=0)\n",
    "f1 = f1_score(labels, preds, zero_division=0)\n",
    "\n",
    "print(f\"\\nDetailed metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(labels, preds)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Plot confusion matrix with percentages\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=['Negative', 'Positive'],\n",
    "    yticklabels=['Negative', 'Positive']\n",
    ")\n",
    "plt.title('BERTweet Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "# Check for any class imbalance in predictions\n",
    "unique, counts = np.unique(preds, return_counts=True)\n",
    "pred_distribution = dict(zip(unique, counts))\n",
    "print(f\"\\nPrediction distribution: {pred_distribution}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab2581b",
   "metadata": {},
   "source": [
    "## 11. Save the Model in PKL Format\n",
    "\n",
    "Save the fine-tuned model, tokenizer, and a prediction function for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0626feb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_path = \"./bertweet-sentiment-finetuned\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n",
    "\n",
    "# Create an improved prediction function\n",
    "def predict_sentiment(texts, model=model, tokenizer=tokenizer):\n",
    "    \"\"\"Predicts sentiment for a list of texts with proper error handling\"\"\"\n",
    "    if not isinstance(texts, list):\n",
    "        texts = [texts]  # Handle single text input\n",
    "    \n",
    "    # Normalize tweets\n",
    "    normalized_texts = [safe_normalize(text) for text in texts]\n",
    "    \n",
    "    # Tokenize with error handling\n",
    "    try:\n",
    "        inputs = tokenizer(normalized_texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "        \n",
    "        # Move to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "            model.cuda()\n",
    "        \n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        # Get probabilities and predictions\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        preds = torch.argmax(probs, dim=-1)\n",
    "        \n",
    "        # Move back to CPU for processing\n",
    "        preds = preds.cpu().numpy()\n",
    "        probs = probs.cpu().numpy()\n",
    "        \n",
    "        results = []\n",
    "        for i, pred in enumerate(preds):\n",
    "            sentiment = \"Positive\" if pred == 1 else \"Negative\"\n",
    "            confidence = probs[i][pred]\n",
    "            results.append({\n",
    "                \"text\": texts[i],\n",
    "                \"sentiment\": sentiment,\n",
    "                \"confidence\": float(confidence),  # Convert numpy float to Python float\n",
    "                \"probabilities\": {\"negative\": float(probs[i][0]), \"positive\": float(probs[i][1])}\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {str(e)}\")\n",
    "        return [{\"text\": text, \"error\": str(e)} for text in texts]\n",
    "\n",
    "# Save the function with the model and tokenizer\n",
    "model_package = {\n",
    "    \"model\": model,\n",
    "    \"tokenizer\": tokenizer,\n",
    "    \"predict_function\": predict_sentiment\n",
    "}\n",
    "\n",
    "joblib.dump(model_package, \"bertweet_sentiment_model.pkl\")\n",
    "print(\"Model saved as bertweet_sentiment_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0626feb8",
   "metadata": {},
   "source": [
    "## 12. Test the Saved Model\n",
    "\n",
    "Load the saved model and test it with some example tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e922a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model package\n",
    "loaded_package = joblib.load(\"bertweet_sentiment_model.pkl\")\n",
    "\n",
    "# Extract components\n",
    "loaded_predict_function = loaded_package[\"predict_function\"]\n",
    "\n",
    "# Test with some example tweets\n",
    "test_tweets = [\n",
    "    \"I absolutely love this new phone! The battery life is amazing! #happy\",\n",
    "    \"This service is terrible. I've been waiting for hours and still no response. #angry\",\n",
    "    \"Just received my order. Can't wait to try it out.\",\n",
    "    \"The weather today is quite nice.\",\n",
    "    \"I'm so disappointed with the quality of this product. ðŸ˜¡\"\n",
    "]\n",
    "\n",
    "# Get predictions\n",
    "results = loaded_predict_function(test_tweets)\n",
    "\n",
    "# Display results\n",
    "for result in results:\n",
    "    print(f\"Text: {result['text']}\")\n",
    "    print(f\"Sentiment: {result['sentiment']} (confidence: {result['confidence']:.4f})\")\n",
    "    print(f\"Probabilities: Negative: {result['probabilities']['negative']:.4f}, Positive: {result['probabilities']['positive']:.4f}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e922a98",
   "metadata": {},
   "source": [
    "## 13. Batch Processing Function\n",
    "\n",
    "Create an improved function for batch processing with error handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeecadec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(texts, model_path=\"bertweet_sentiment_model.pkl\", batch_size=32):\n",
    "    \"\"\"\n",
    "    Loads the saved BERTweet model package, normalizes the texts,\n",
    "    and returns the sentiment predictions with batching for efficiency.\n",
    "    \"\"\"\n",
    "    # Load model package\n",
    "    try:\n",
    "        package = joblib.load(model_path)\n",
    "        model = package[\"model\"]\n",
    "        tokenizer = package[\"tokenizer\"]\n",
    "        \n",
    "        # Move model to GPU if available\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        # Process in batches\n",
    "        results = []\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            \n",
    "            # Normalize texts\n",
    "            normalized_texts = [safe_normalize(text) for text in batch_texts]\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = tokenizer(normalized_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            \n",
    "            # Get predictions\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "            \n",
    "            # Get probabilities and predictions\n",
    "            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            preds = torch.argmax(probs, dim=-1)\n",
    "            \n",
    "            # Move back to CPU\n",
    "            preds = preds.cpu().numpy()\n",
    "            probs = probs.cpu().numpy()\n",
    "            \n",
    "            for j, pred in enumerate(preds):\n",
    "                results.append({\n",
    "                    \"text\": batch_texts[j],\n",
    "                    \"sentiment\": \"Positive\" if pred == 1 else \"Negative\",\n",
    "                    \"pred_label\": int(pred),\n",
    "                    \"confidence\": float(probs[j][pred]),\n",
    "                    \"negative_prob\": float(probs[j][0]),\n",
    "                    \"positive_prob\": float(probs[j][1])\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in batch_predict: {str(e)}\")\n",
    "        return [{\"error\": str(e), \"text\": text} for text in texts]\n",
    "\n",
    "# Example usage\n",
    "sample_texts = [\"I love this product!\", \"This is the worst experience ever.\", \"The weather is nice today.\"]\n",
    "batch_results = batch_predict(sample_texts)\n",
    "print(\"Batch prediction results:\")\n",
    "for result in batch_results:\n",
    "    print(f\"Text: {result['text']}\")\n",
    "    print(f\"Sentiment: {result['sentiment']} (confidence: {result['confidence']:.4f})\")\n",
    "    print(f\"Negative prob: {result['negative_prob']:.4f}, Positive prob: {result['positive_prob']:.4f}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a226094",
   "metadata": {},
   "source": [
    "## 14. Error Analysis & Model Interpretability\n",
    "\n",
    "Let's analyze some of the model's errors and understand why it makes certain predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56f6e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample of test predictions to analyze errors\n",
    "test_texts = test_df['normalized_text'].tolist()[:50]  # Use a smaller sample for quicker analysis\n",
    "true_labels = test_df['target'].tolist()[:50]\n",
    "\n",
    "# Get predictions\n",
    "error_analysis_results = batch_predict(test_texts)\n",
    "\n",
    "# Find examples of errors\n",
    "errors = []\n",
    "for i, result in enumerate(error_analysis_results):\n",
    "    pred_label = result['pred_label']\n",
    "    true_label = true_labels[i]\n",
    "    confidence = result['confidence']\n",
    "    \n",
    "    if pred_label != true_label:\n",
    "        errors.append({\n",
    "            \"text\": result['text'],\n",
    "            \"true_sentiment\": \"Positive\" if true_label == 1 else \"Negative\",\n",
    "            \"predicted_sentiment\": result['sentiment'],\n",
    "            \"confidence\": confidence,\n",
    "            \"neg_prob\": result['negative_prob'],\n",
    "            \"pos_prob\": result['positive_prob']\n",
    "        })\n",
    "\n",
    "# Display some errors\n",
    "print(f\"Found {len(errors)} errors in the sample\")\n",
    "print(\"\\nSample of errors:\")\n",
    "for i, error in enumerate(errors[:5]):  # Show first 5 errors\n",
    "    print(f\"Error {i+1}:\")\n",
    "    print(f\"Text: {error['text']}\")\n",
    "    print(f\"True: {error['true_sentiment']}, Predicted: {error['predicted_sentiment']} (confidence: {error['confidence']:.4f})\")\n",
    "    print(f\"Negative prob: {error['neg_prob']:.4f}, Positive prob: {error['pos_prob']:.4f}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74db9d4",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We've successfully fixed the BERTweet fine-tuning process using a small sample size for quick testing and validation. The key improvements include:\n",
    "\n",
    "1. Using a small sample (5,000 tweets) to quickly test the pipeline\n",
    "2. Implementing class balancing to ensure equal representation of positive and negative tweets\n",
    "3. Adding weighted loss function to handle class imbalance\n",
    "4. Using proper metrics with zero_division handling\n",
    "5. Including validation during training to monitor progress\n",
    "6. Adding error analysis to understand model predictions\n",
    "\n",
    "With this approach, you can quickly validate your fine-tuning pipeline and ensure it works correctly before scaling up to larger datasets. To improve model performance on real-world data, simply increase the `sample_size` variable in the data preparation step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b617bd0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94d663d9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
